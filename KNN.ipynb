{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ff3d1b-876d-4ac9-b178-3bb446bad492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data\n",
    "\n",
    "import random\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b1c826-3d80-4186-92d5-af291864285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 examples of training data:\n",
      "[[26.94933313 26.94942352 26.86116345 ... 16.22032493 17.53295088\n",
      "  17.53075379]\n",
      " [26.95540644 26.95561349 26.86818211 ... 16.22077216 17.53405894\n",
      "  17.53186146]\n",
      " [26.96394591 26.96354065 26.87468671 ... 16.22162589 17.53570343\n",
      "  17.53347345]\n",
      " ...\n",
      " [26.95091461 26.95146416 26.85930528 ... 16.21242109 17.53291899\n",
      "  17.53075099]\n",
      " [26.93989902 26.94184343 26.84918537 ... 16.21115102 17.5320002\n",
      "  17.52995518]\n",
      " [26.92817907 26.9306008  26.83702679 ... 16.21079389 17.53139138\n",
      "  17.52946743]]\n",
      "\n",
      "Corresponding labels for the training data:\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "First 10 examples of test data:\n",
      "[[26.88684078 26.36006069 26.2375236  ... 16.32757215 16.90493887\n",
      "  16.7821357 ]\n",
      " [26.88612478 26.35698842 26.23444401 ... 16.33011158 16.90430262\n",
      "  16.78066285]\n",
      " [26.88125864 26.3487917  26.22622124 ... 16.33296166 16.90424512\n",
      "  16.77954978]\n",
      " ...\n",
      " [26.83513111 26.27179449 26.16101443 ... 16.31236921 16.87338631\n",
      "  16.74132307]\n",
      " [26.82404048 26.25446281 26.14994268 ... 16.30692625 16.86661873\n",
      "  16.73289937]\n",
      " [26.81532266 26.24281711 26.13940717 ... 16.30125824 16.85990699\n",
      "  16.72438165]]\n",
      "\n",
      "Corresponding labels for the test data:\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "Total number of samples in the dataset: 84420\n"
     ]
    }
   ],
   "source": [
    "data = load_data.read_data_sets()\n",
    "\n",
    "# get train data\n",
    "train_x = data.train.data\n",
    "\n",
    "# get train labels\n",
    "train_labels = data.train.labels\n",
    "\n",
    "# get test data\n",
    "test_x = data.test.data\n",
    "\n",
    "# get test labels\n",
    "test_labels = data.test.labels\n",
    "\n",
    "# get sample number\n",
    "n_samples = data.train.num_examples\n",
    "\n",
    "# Print the first 10 examples of training data and labels\n",
    "print(\"First 10 examples of training data:\")\n",
    "print(train_x[:10])\n",
    "print()\n",
    "\n",
    "print(\"Corresponding labels for the training data:\")\n",
    "print(train_labels[:10])\n",
    "print()\n",
    "\n",
    "# Print the first 10 examples of test data and labels\n",
    "print(\"First 10 examples of test data:\")\n",
    "print(test_x[:10])\n",
    "print()\n",
    "\n",
    "print(\"Corresponding labels for the test data:\")\n",
    "print(test_labels[:10])\n",
    "print()\n",
    "\n",
    "# Print the total number of samples in the dataset\n",
    "print(f\"Total number of samples in the dataset: {n_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c514abfe-7272-42cc-819e-86fc1c9f8d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label counts: {0: 28602, 1: 26628, 2: 29190}\n",
      "Test label counts: {0: 18438, 1: 19740, 2: 19950}\n"
     ]
    }
   ],
   "source": [
    "# Count the unique labels in the training set\n",
    "unique_train, counts_train = np.unique(train_labels, return_counts=True)\n",
    "label_counts_train = dict(zip(unique_train, counts_train))\n",
    "\n",
    "# Count the unique labels in the test set\n",
    "unique_test, counts_test = np.unique(test_labels, return_counts=True)\n",
    "label_counts_test = dict(zip(unique_test, counts_test))\n",
    "\n",
    "print(\"Training label counts:\", label_counts_train)\n",
    "print(\"Test label counts:\", label_counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc87781-c837-4338-8f27-8eba9962c40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset has missing values\n",
    "missing_rows_count = np.isnan(train_x).any(axis=1).sum()\n",
    "print(f\"Number of rows with missing values: {missing_rows_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b9609a5-bd68-4318-b085-9e3ad916f974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label counts after balancing: {0: 29190, 1: 29190, 2: 29190}\n"
     ]
    }
   ],
   "source": [
    "# Balance the training data using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "balanced_train_x, balanced_train_labels = smote.fit_resample(train_x, train_labels)\n",
    "\n",
    "unique_train1, counts_train1 = np.unique(balanced_train_labels, return_counts=True)\n",
    "label_counts_train1 = dict(zip(unique_train1, counts_train1))\n",
    "\n",
    "print(\"Training label counts after balancing:\", label_counts_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5290fa9b-0b55-4e2c-95ed-de32921c95b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 shuffled training labels\n",
      "[1 1 0 1 0 2 0 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle indices\n",
    "indices = np.arange(balanced_train_x.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Use shuffled indices to shuffle train_x and train_labels\n",
    "balanced_train_x_shuffled = balanced_train_x[indices]\n",
    "balanced_train_labels_shuffled = balanced_train_labels[indices]\n",
    "\n",
    "# Print the first 10 examples of shuffled training labels\n",
    "print(\"First 10 shuffled training labels\")\n",
    "print(balanced_train_labels_shuffled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7277337e-fa3e-4c33-845a-e30069a0179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "balanced_train_labels_shuffled_encoded = to_categorical(balanced_train_labels_shuffled, num_classes=3)\n",
    "test_labels_encoded = to_categorical(test_labels, num_classes=3)\n",
    "\n",
    "print(balanced_train_labels_shuffled_encoded[:10])\n",
    "print(test_labels_encoded[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c4b5d3-211e-4505-9df6-b259480726eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 examples of training data:\n",
      "[[-0.80897752 -0.92976601 -0.98176373 ... -0.4226777  -0.46305283\n",
      "  -0.29038858]\n",
      " [ 1.35138844  1.19191092  0.93874673 ... -0.05225323 -0.68985171\n",
      "  -0.70933933]\n",
      " [-0.10339723  0.06185361 -0.278523   ... -1.5767544  -1.74401209\n",
      "  -1.38143393]\n",
      " ...\n",
      " [ 0.12316061 -0.23472422 -0.52575232 ... -0.55952438 -0.96126969\n",
      "  -0.3948382 ]\n",
      " [ 0.60142778  0.5319706   0.73674664 ...  1.62385263  1.09290431\n",
      "   1.14691356]\n",
      " [-0.02586467 -0.07392972 -0.08909469 ... -0.19447868 -0.32800766\n",
      "  -0.3368985 ]]\n",
      "\n",
      "Corresponding labels for the training data:\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "\n",
      "One-Hot encoded labels for the training data:\n",
      "[1 1 0 1 0 2 0 1 2 0]\n",
      "\n",
      "First 10 examples of test data:\n",
      "[[ 0.44138796 -0.00202854 -0.1746563  ... -0.41053994 -0.00116352\n",
      "  -0.22655811]\n",
      " [ 0.4407388  -0.00470152 -0.17757255 ... -0.40779565 -0.0018294\n",
      "  -0.22787341]\n",
      " [ 0.43632692 -0.01183294 -0.18535919 ... -0.40471564 -0.00188958\n",
      "  -0.22886742]\n",
      " ...\n",
      " [ 0.3945054  -0.07882315 -0.2471074  ... -0.42696935 -0.03418553\n",
      "  -0.26300493]\n",
      " [ 0.38445009 -0.09390231 -0.25759189 ... -0.4328514  -0.04126829\n",
      "  -0.27052752]\n",
      " [ 0.37654608 -0.10403446 -0.2675686  ... -0.43897667 -0.0482926\n",
      "  -0.27813409]]\n",
      "\n",
      "Corresponding labels for the test data:\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "One-Hot encoded labels for the test data:\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(balanced_train_x_shuffled)\n",
    "X_test = scaler.transform(test_x)\n",
    "\n",
    "y_train = balanced_train_labels_shuffled_encoded\n",
    "y_test = test_labels_encoded\n",
    "\n",
    "y_train1 = balanced_train_labels_shuffled\n",
    "y_test1 = test_labels\n",
    "\n",
    "print(\"First 10 examples of training data:\")\n",
    "print(X_train[:10])\n",
    "print()\n",
    "\n",
    "print(\"Corresponding labels for the training data:\")\n",
    "print(y_train[:10])\n",
    "print()\n",
    "\n",
    "print(\"One-Hot encoded labels for the training data:\")\n",
    "print(y_train1[:10])\n",
    "print()\n",
    "\n",
    "print(\"First 10 examples of test data:\")\n",
    "print(X_test[:10])\n",
    "print()\n",
    "\n",
    "print(\"Corresponding labels for the test data:\")\n",
    "print(y_test[:10])\n",
    "print()\n",
    "\n",
    "print(\"One-Hot encoded labels for the test data:\")\n",
    "print(y_test1[:10])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30f1ff54-c2dd-45ba-9b17-73a8e2ab8fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: {'n_neighbors': 3, 'leaf_size': 10}\n",
      "Test accuracy: 75.5591%\n",
      "Saved the best model with accuracy: 75.5591%\n",
      "\n",
      "Training with params: {'n_neighbors': 3, 'leaf_size': 20}\n",
      "Test accuracy: 75.5591%\n",
      "\n",
      "Training with params: {'n_neighbors': 3, 'leaf_size': 30}\n",
      "Test accuracy: 75.5591%\n",
      "\n",
      "Training with params: {'n_neighbors': 3, 'leaf_size': 40}\n",
      "Test accuracy: 75.5591%\n",
      "\n",
      "Training with params: {'n_neighbors': 3, 'leaf_size': 50}\n",
      "Test accuracy: 75.5591%\n",
      "\n",
      "Training with params: {'n_neighbors': 5, 'leaf_size': 10}\n",
      "Test accuracy: 75.5746%\n",
      "Saved the best model with accuracy: 75.5746%\n",
      "\n",
      "Training with params: {'n_neighbors': 5, 'leaf_size': 20}\n",
      "Test accuracy: 75.5746%\n",
      "\n",
      "Training with params: {'n_neighbors': 5, 'leaf_size': 30}\n",
      "Test accuracy: 75.5746%\n",
      "\n",
      "Training with params: {'n_neighbors': 5, 'leaf_size': 40}\n",
      "Test accuracy: 75.5746%\n",
      "\n",
      "Training with params: {'n_neighbors': 5, 'leaf_size': 50}\n",
      "Test accuracy: 75.5746%\n",
      "\n",
      "Training with params: {'n_neighbors': 7, 'leaf_size': 10}\n",
      "Test accuracy: 75.5884%\n",
      "Saved the best model with accuracy: 75.5884%\n",
      "\n",
      "Training with params: {'n_neighbors': 7, 'leaf_size': 20}\n",
      "Test accuracy: 75.5884%\n",
      "\n",
      "Training with params: {'n_neighbors': 7, 'leaf_size': 30}\n",
      "Test accuracy: 75.5884%\n",
      "\n",
      "Training with params: {'n_neighbors': 7, 'leaf_size': 40}\n",
      "Test accuracy: 75.5884%\n",
      "\n",
      "Training with params: {'n_neighbors': 7, 'leaf_size': 50}\n",
      "Test accuracy: 75.5884%\n",
      "\n",
      "Training with params: {'n_neighbors': 9, 'leaf_size': 10}\n",
      "Test accuracy: 75.5970%\n",
      "Saved the best model with accuracy: 75.5970%\n",
      "\n",
      "Training with params: {'n_neighbors': 9, 'leaf_size': 20}\n",
      "Test accuracy: 75.5970%\n",
      "\n",
      "Training with params: {'n_neighbors': 9, 'leaf_size': 30}\n",
      "Test accuracy: 75.5970%\n",
      "\n",
      "Training with params: {'n_neighbors': 9, 'leaf_size': 40}\n",
      "Test accuracy: 75.5970%\n",
      "\n",
      "Training with params: {'n_neighbors': 9, 'leaf_size': 50}\n",
      "Test accuracy: 75.5970%\n",
      "\n",
      "Training with params: {'n_neighbors': 11, 'leaf_size': 10}\n",
      "Test accuracy: 75.6296%\n",
      "Saved the best model with accuracy: 75.6296%\n",
      "\n",
      "Training with params: {'n_neighbors': 11, 'leaf_size': 20}\n",
      "Test accuracy: 75.6296%\n",
      "\n",
      "Training with params: {'n_neighbors': 11, 'leaf_size': 30}\n",
      "Test accuracy: 75.6296%\n",
      "\n",
      "Training with params: {'n_neighbors': 11, 'leaf_size': 40}\n",
      "Test accuracy: 75.6296%\n",
      "\n",
      "Training with params: {'n_neighbors': 11, 'leaf_size': 50}\n",
      "Test accuracy: 75.6296%\n",
      "\n",
      "Best accuracy of K-Nearest Neighbors: 75.6296% with params: {'n_neighbors': 11, 'leaf_size': 10}\n"
     ]
    }
   ],
   "source": [
    "# Suppress convergence warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define parameter grid for KNN\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    #'weights': ['uniform', 'distance'],\n",
    "    #'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "# Initialize best accuracy and hyperparameters\n",
    "best_accuracy_knn = 0\n",
    "best_params_knn = {}\n",
    "best_model_path = 'Best_KNN_model.pkl'\n",
    "\n",
    "# Loop over parameter combinations 'weights': weights, 'algorithm': algorithm,\n",
    "for params in [{'n_neighbors': n_neighbors, 'leaf_size': leaf_size} \n",
    "               for n_neighbors in param_grid_knn['n_neighbors'] \n",
    "               #for weights in param_grid_knn['weights'] \n",
    "               #for algorithm in param_grid_knn['algorithm'] \n",
    "               for leaf_size in param_grid_knn['leaf_size']]:\n",
    "    try:\n",
    "        print(f\"Training with params: {params}\")\n",
    "        \n",
    "        # Create the KNN model\n",
    "        knn = KNeighborsClassifier(n_neighbors=params['n_neighbors'], weights='uniform', \n",
    "                                   algorithm='auto', leaf_size=params['leaf_size'])\n",
    "        \n",
    "        # Fit the model\n",
    "        knn.fit(X_train, y_train1)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred = knn.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test1, y_pred)\n",
    "        print(f\"Test accuracy: {accuracy:.4%}\")\n",
    "        \n",
    "        # Check if this model is the best so far\n",
    "        if accuracy > best_accuracy_knn:\n",
    "            best_accuracy_knn = accuracy\n",
    "            best_params_knn = params\n",
    "            joblib.dump(knn, best_model_path)\n",
    "            print(f\"Saved the best model with accuracy: {accuracy:.4%}\")\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping parameters {params} due to error: {e}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Best accuracy of K-Nearest Neighbors: {best_accuracy_knn:.4%} with params: {best_params_knn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
