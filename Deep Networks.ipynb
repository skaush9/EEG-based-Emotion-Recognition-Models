{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033f15db-0cc2-40ee-bfae-174b06808cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, ReLU, Flatten, Dense, Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5f4dc0-001a-4e22-8330-6fbb15da688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 examples of training data:\n",
      "[[26.94933313 26.94942352 26.86116345 ... 16.22032493 17.53295088\n",
      "  17.53075379]\n",
      " [26.95540644 26.95561349 26.86818211 ... 16.22077216 17.53405894\n",
      "  17.53186146]\n",
      " [26.96394591 26.96354065 26.87468671 ... 16.22162589 17.53570343\n",
      "  17.53347345]\n",
      " ...\n",
      " [26.95091461 26.95146416 26.85930528 ... 16.21242109 17.53291899\n",
      "  17.53075099]\n",
      " [26.93989902 26.94184343 26.84918537 ... 16.21115102 17.5320002\n",
      "  17.52995518]\n",
      " [26.92817907 26.9306008  26.83702679 ... 16.21079389 17.53139138\n",
      "  17.52946743]]\n",
      "\n",
      "Corresponding labels for the training data:\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "First 10 examples of test data:\n",
      "[[26.88684078 26.36006069 26.2375236  ... 16.32757215 16.90493887\n",
      "  16.7821357 ]\n",
      " [26.88612478 26.35698842 26.23444401 ... 16.33011158 16.90430262\n",
      "  16.78066285]\n",
      " [26.88125864 26.3487917  26.22622124 ... 16.33296166 16.90424512\n",
      "  16.77954978]\n",
      " ...\n",
      " [26.83513111 26.27179449 26.16101443 ... 16.31236921 16.87338631\n",
      "  16.74132307]\n",
      " [26.82404048 26.25446281 26.14994268 ... 16.30692625 16.86661873\n",
      "  16.73289937]\n",
      " [26.81532266 26.24281711 26.13940717 ... 16.30125824 16.85990699\n",
      "  16.72438165]]\n",
      "\n",
      "Corresponding labels for the test data:\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "Total number of samples in the dataset: 84420\n"
     ]
    }
   ],
   "source": [
    "data = load_data.read_data_sets()\n",
    "\n",
    "# get train data\n",
    "train_x = data.train.data\n",
    "\n",
    "# get train labels\n",
    "train_labels = data.train.labels\n",
    "\n",
    "# get test data\n",
    "test_x = data.test.data\n",
    "\n",
    "# get test labels\n",
    "test_labels = data.test.labels\n",
    "\n",
    "# get sample number\n",
    "n_samples = data.train.num_examples\n",
    "\n",
    "# Print the first 10 examples of training data and labels\n",
    "print(\"First 10 examples of training data:\")\n",
    "print(train_x[:10])\n",
    "print()\n",
    "\n",
    "print(\"Corresponding labels for the training data:\")\n",
    "print(train_labels[:10])\n",
    "print()\n",
    "\n",
    "# Print the first 10 examples of test data and labels\n",
    "print(\"First 10 examples of test data:\")\n",
    "print(test_x[:10])\n",
    "print()\n",
    "\n",
    "print(\"Corresponding labels for the test data:\")\n",
    "print(test_labels[:10])\n",
    "print()\n",
    "\n",
    "# Print the total number of samples in the dataset\n",
    "print(f\"Total number of samples in the dataset: {n_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10be10f0-b5aa-4b9e-a63d-e7247f9c7e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label counts: {0: 28602, 1: 26628, 2: 29190}\n",
      "Test label counts: {0: 18438, 1: 19740, 2: 19950}\n"
     ]
    }
   ],
   "source": [
    "# Count the unique labels in the training set\n",
    "unique_train, counts_train = np.unique(train_labels, return_counts=True)\n",
    "label_counts_train = dict(zip(unique_train, counts_train))\n",
    "\n",
    "# Count the unique labels in the test set\n",
    "unique_test, counts_test = np.unique(test_labels, return_counts=True)\n",
    "label_counts_test = dict(zip(unique_test, counts_test))\n",
    "\n",
    "print(\"Training label counts:\", label_counts_train)\n",
    "print(\"Test label counts:\", label_counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b64fe5c-89e8-4757-842f-79d3c0ba4b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset has missing values\n",
    "missing_rows_count = np.isnan(train_x).any(axis=1).sum()\n",
    "print(f\"Number of rows with missing values: {missing_rows_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f86271d3-e28d-4e89-8865-c461e20335dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label counts after balancing: {0: 29190, 1: 29190, 2: 29190}\n"
     ]
    }
   ],
   "source": [
    "# Balance the training data using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "balanced_train_x, balanced_train_labels = smote.fit_resample(train_x, train_labels)\n",
    "\n",
    "unique_train1, counts_train1 = np.unique(balanced_train_labels, return_counts=True)\n",
    "label_counts_train1 = dict(zip(unique_train1, counts_train1))\n",
    "\n",
    "print(\"Training label counts after balancing:\", label_counts_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe0ad56-89dc-4f8d-931a-70ca1b8cd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 shuffled training labels\n",
      "[0 0 2 0 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle indices\n",
    "indices = np.arange(balanced_train_x.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Use shuffled indices to shuffle train_x and train_labels\n",
    "balanced_train_x_shuffled = balanced_train_x[indices]\n",
    "balanced_train_labels_shuffled = balanced_train_labels[indices]\n",
    "\n",
    "# Print the first 10 examples of shuffled training labels\n",
    "print(\"First 10 shuffled training labels\")\n",
    "print(balanced_train_labels_shuffled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b083fc06-6fd5-4223-a065-fee8f9f12fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "balanced_train_labels_shuffled_encoded = to_categorical(balanced_train_labels_shuffled, num_classes=3)\n",
    "test_labels_encoded = to_categorical(test_labels, num_classes=3)\n",
    "\n",
    "print(balanced_train_labels_shuffled_encoded[:10])\n",
    "print(test_labels_encoded[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d46b02d-ac54-4298-93b7-e421e8e7eee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 examples of training data:\n",
      "[[ 1.91514221  1.9268096   1.04813218 ...  0.29733114  0.16230917\n",
      "   0.35768258]\n",
      " [ 0.91635726  0.66241251  0.97348119 ...  0.75976295  0.06117537\n",
      "  -0.25740715]\n",
      " [ 0.95691734  1.06908794  0.9078273  ... -0.02796822  0.26752087\n",
      "   0.1176113 ]\n",
      " ...\n",
      " [-0.52247861 -0.83248713 -1.12225529 ... -0.39899161 -0.56656156\n",
      "  -0.70546815]\n",
      " [-0.36918854 -0.33864369 -0.10770834 ... -0.05882406  1.08139682\n",
      "   0.80224198]\n",
      " [-1.00283028 -1.0909438  -1.40705465 ... -0.90723556 -0.47301159\n",
      "   0.02493582]]\n",
      "\n",
      "Corresponding labels for the training data:\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "\n",
      "One-Hot encoded labels for the training data:\n",
      "[0 0 2 0 0 1 1 1 0 0]\n",
      "\n",
      "First 10 examples of test data:\n",
      "[[ 0.44138796 -0.00202854 -0.1746563  ... -0.41053994 -0.00116352\n",
      "  -0.22655811]\n",
      " [ 0.4407388  -0.00470152 -0.17757255 ... -0.40779565 -0.0018294\n",
      "  -0.22787341]\n",
      " [ 0.43632692 -0.01183294 -0.18535919 ... -0.40471564 -0.00188958\n",
      "  -0.22886742]\n",
      " ...\n",
      " [ 0.3945054  -0.07882315 -0.2471074  ... -0.42696935 -0.03418553\n",
      "  -0.26300493]\n",
      " [ 0.38445009 -0.09390231 -0.25759189 ... -0.4328514  -0.04126829\n",
      "  -0.27052752]\n",
      " [ 0.37654608 -0.10403446 -0.2675686  ... -0.43897667 -0.0482926\n",
      "  -0.27813409]]\n",
      "\n",
      "Corresponding labels for the test data:\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "One-Hot encoded labels for the test data:\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(balanced_train_x_shuffled)\n",
    "X_test = scaler.transform(test_x)\n",
    "\n",
    "y_train = balanced_train_labels_shuffled_encoded\n",
    "y_test = test_labels_encoded\n",
    "\n",
    "y_train1 = balanced_train_labels_shuffled\n",
    "y_test1 = test_labels\n",
    "\n",
    "print(\"First 10 examples of training data:\")\n",
    "print(X_train[:10])\n",
    "print()\n",
    "\n",
    "print(\"Corresponding labels for the training data:\")\n",
    "print(y_train[:10])\n",
    "print()\n",
    "\n",
    "print(\"One-Hot encoded labels for the training data:\")\n",
    "print(y_train1[:10])\n",
    "print()\n",
    "\n",
    "print(\"First 10 examples of test data:\")\n",
    "print(X_test[:10])\n",
    "print()\n",
    "\n",
    "print(\"Corresponding labels for the test data:\")\n",
    "print(y_test[:10])\n",
    "print()\n",
    "\n",
    "print(\"One-Hot encoded labels for the test data:\")\n",
    "print(y_test1[:10])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fb449a0-fcd8-4095-907d-720e2ee4545b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: {'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "Test accuracy: 78.9740%\n",
      "Saved the best model with accuracy: 78.9740%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "Test accuracy: 76.9010%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "Test accuracy: 38.6647%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "Test accuracy: 77.9211%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "Test accuracy: 76.9371%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "Test accuracy: 77.0472%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "Test accuracy: 77.9745%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "Test accuracy: 77.7147%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "Test accuracy: 40.6861%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "Test accuracy: 38.6079%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "Test accuracy: 78.3719%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "Test accuracy: 76.6997%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "Test accuracy: 76.9767%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "Test accuracy: 77.0369%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 15, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "Test accuracy: 78.0433%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "Test accuracy: 78.3942%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "Test accuracy: 38.6888%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "Test accuracy: 80.3623%\n",
      "Saved the best model with accuracy: 80.3623%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "Test accuracy: 76.8700%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "Test accuracy: 77.6356%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "Test accuracy: 77.0971%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "Test accuracy: 78.9946%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "Test accuracy: 71.1998%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "Test accuracy: 79.9769%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "Test accuracy: 76.5965%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "Test accuracy: 78.1087%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Best accuracy: 80.3623% with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_shape = 310\n",
    "num_classes = 3  \n",
    "\n",
    "# Function to create the model\n",
    "def create_dcnet_GS(input_shape, num_classes, optimizer, learning_rate, regularization):\n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    \n",
    "    # Reshape the input to match the initial input shape for the deconvolution phase\n",
    "    x = Reshape((1, 1, input_shape))(inputs)\n",
    "\n",
    "    # Deconvolution Phase\n",
    "    x = Conv2DTranspose(512, (2, 2), strides=(1, 1))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(256, (3, 3), strides=(1, 1))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(128, (5, 5), strides=(1, 1))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(64, (9, 9), strides=(1, 1))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(3, (9, 9), strides=(1, 1))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(1, (9, 9), strides=(1, 1))(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Convolution Phase with regularization\n",
    "    x = Conv2D(3, (1, 1), strides=(1, 1), kernel_regularizer=l2(regularization))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(128, (1, 1), strides=(1, 1), kernel_regularizer=l2(regularization))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(256, (1, 1), strides=(1, 1), kernel_regularizer=l2(regularization))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(512, (1, 1), strides=(1, 1), kernel_regularizer=l2(regularization))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Fully-connected layer with regularization\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(3, activation='softmax', kernel_regularizer=l2(regularization))(x)\n",
    "\n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "    # Select optimizer and compile the model\n",
    "    if optimizer == 'Adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer}\")\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define grid search parameters\n",
    "param_grid_dcn = {\n",
    "    'optimizer': ['Adam', 'SGD', 'RMSprop'],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'regularization': [0.01, 0.001],\n",
    "    'epochs': [10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "# Initialize best accuracy and hyperparameters\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "best_model_path = 'Best_DCNet_model.h5'\n",
    "\n",
    "# Loop over parameter combinations\n",
    "for params in ParameterGrid(param_grid_dcn):\n",
    "    print(f\"Training with params: {params}\")\n",
    "    \n",
    "    # Create model\n",
    "    model_GS = create_dcnet_GS(input_shape, num_classes, params['optimizer'], params['learning_rate'], params['regularization'])\n",
    "    \n",
    "    # Train the model\n",
    "    history_GS = model_GS.fit(X_train, y_train, epochs=params['epochs'], batch_size=64, validation_split=0.1, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model_GS.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test accuracy: {accuracy:.4%}\")\n",
    "    \n",
    "    # Check if this model is the best so far\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params\n",
    "\n",
    "        # Save the model\n",
    "        model_GS.save(best_model_path)\n",
    "        print(f\"Saved the best model with accuracy: {accuracy:.4%}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "print(f\"Best accuracy: {best_accuracy:.4%} with params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d3ea3a6-e823-4729-8176-fbe552adf7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1817/1817 [==============================] - 8s 4ms/step - loss: 2.5347 - accuracy: 0.8036\n",
      "Test accuracy: 80.3623%\n"
     ]
    }
   ],
   "source": [
    "best_model_path = 'Best_DCNet_model.h5'\n",
    "Best_Model_DCNet = tf.keras.models.load_model(best_model_path)\n",
    "\n",
    "loss, accuracy = Best_Model_DCNet.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57425030-a792-4e0b-a6a1-f2ecc02520d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(43)\n",
    "random.seed(43)\n",
    "tf.random.set_seed(43)\n",
    "\n",
    "def create_nn(input_shape, num_classes, optimizer, learning_rate, regularization):\n",
    "    model = Sequential([\n",
    "        Dense(620, activation='relu', input_shape=(input_shape,), kernel_regularizer=l2(regularization)),\n",
    "        Dense(310, activation='relu', kernel_regularizer=l2(regularization)),\n",
    "        Dense(155, activation='relu', kernel_regularizer=l2(regularization)),\n",
    "        Dense(72, activation='relu', kernel_regularizer=l2(regularization)),\n",
    "        Dense(12, activation='relu', kernel_regularizer=l2(regularization)),\n",
    "        Dense(3, activation='softmax', kernel_regularizer=l2(regularization))\n",
    "    ])\n",
    "\n",
    "    # Select optimizer and compile the model\n",
    "    if optimizer == 'Adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer}\")\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04fa942d-c33b-40e3-b22c-ac3beddee21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: {'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1125 - accuracy: 0.7550\n",
      "Test accuracy: 75.5006%\n",
      "\n",
      "Saved the best model with accuracy: 75.5006%\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.0990 - accuracy: 0.7819\n",
      "Test accuracy: 78.1930%\n",
      "\n",
      "Saved the best model with accuracy: 78.1930%\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 7.8712 - accuracy: 0.7554\n",
      "Test accuracy: 75.5436%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.9069 - accuracy: 0.7642\n",
      "Test accuracy: 76.4244%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.2119 - accuracy: 0.7467\n",
      "Test accuracy: 74.6714%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1744 - accuracy: 0.7744\n",
      "Test accuracy: 77.4429%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1005 - accuracy: 0.3172\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1005 - accuracy: 0.3172\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 0.9381 - accuracy: 0.7657\n",
      "Test accuracy: 76.5689%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.7279 - accuracy: 0.7581\n",
      "Test accuracy: 75.8120%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1070 - accuracy: 0.6410\n",
      "Test accuracy: 64.0982%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.2990 - accuracy: 0.7344\n",
      "Test accuracy: 73.4414%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1044 - accuracy: 0.3432\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.2255 - accuracy: 0.3432\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1739 - accuracy: 0.7168\n",
      "Test accuracy: 71.6780%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 0.8830 - accuracy: 0.7322\n",
      "Test accuracy: 73.2177%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 12.2083 - accuracy: 0.3432\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 10, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 2.2077 - accuracy: 0.3432\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.2955 - accuracy: 0.7482\n",
      "Test accuracy: 74.8211%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.2961 - accuracy: 0.7552\n",
      "Test accuracy: 75.5195%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 5.1759 - accuracy: 0.7730\n",
      "Test accuracy: 77.2984%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 2.1164 - accuracy: 0.7582\n",
      "Test accuracy: 75.8154%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1125 - accuracy: 0.7598\n",
      "Test accuracy: 75.9840%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.6487 - accuracy: 0.7492\n",
      "Test accuracy: 74.9174%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.0990 - accuracy: 0.3396\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.0990 - accuracy: 0.3396\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 0.8869 - accuracy: 0.7644\n",
      "Test accuracy: 76.4416%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.4627 - accuracy: 0.7789\n",
      "Test accuracy: 77.8850%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.2093 - accuracy: 0.3396\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.5276 - accuracy: 0.7021\n",
      "Test accuracy: 70.2106%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1061 - accuracy: 0.3396\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1042 - accuracy: 0.3396\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1178 - accuracy: 0.7413\n",
      "Test accuracy: 74.1278%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1132 - accuracy: 0.7534\n",
      "Test accuracy: 75.3423%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 12.2085 - accuracy: 0.3396\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 2.2079 - accuracy: 0.3396\n",
      "Test accuracy: 33.9595%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.0157 - accuracy: 0.7644\n",
      "Test accuracy: 76.4399%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.2511 - accuracy: 0.7677\n",
      "Test accuracy: 76.7702%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 3.4898 - accuracy: 0.7727\n",
      "Test accuracy: 77.2743%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.9961 - accuracy: 0.7715\n",
      "Test accuracy: 77.1487%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1168 - accuracy: 0.7563\n",
      "Test accuracy: 75.6331%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.3038 - accuracy: 0.7677\n",
      "Test accuracy: 76.7668%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 16s 9ms/step - loss: 1.0982 - accuracy: 0.3432\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 16s 9ms/step - loss: 1.4435 - accuracy: 0.7440\n",
      "Test accuracy: 74.3962%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 0.8497 - accuracy: 0.7705\n",
      "Test accuracy: 77.0541%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.2095 - accuracy: 0.7713\n",
      "Test accuracy: 77.1263%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.5975 - accuracy: 0.5572\n",
      "Test accuracy: 55.7236%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.2598 - accuracy: 0.7422\n",
      "Test accuracy: 74.2190%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1025 - accuracy: 0.3172\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1009 - accuracy: 0.3172\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.4069 - accuracy: 0.6918\n",
      "Test accuracy: 69.1784%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.0119 - accuracy: 0.7820\n",
      "Test accuracy: 78.1998%\n",
      "\n",
      "Saved the best model with accuracy: 78.1998%\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 4s 2ms/step - loss: 12.2130 - accuracy: 0.3432\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 30, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 2.2124 - accuracy: 0.3432\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.0807 - accuracy: 0.7634\n",
      "Test accuracy: 76.3419%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.0362 - accuracy: 0.7859\n",
      "Test accuracy: 78.5886%\n",
      "\n",
      "Saved the best model with accuracy: 78.5886%\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.8316 - accuracy: 0.7692\n",
      "Test accuracy: 76.9216%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 2.1379 - accuracy: 0.7478\n",
      "Test accuracy: 74.7850%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.2667 - accuracy: 0.7531\n",
      "Test accuracy: 75.3079%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.4813 - accuracy: 0.7638\n",
      "Test accuracy: 76.3763%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1016 - accuracy: 0.3172\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1016 - accuracy: 0.3172\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 0.8237 - accuracy: 0.7826\n",
      "Test accuracy: 78.2635%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 0.9745 - accuracy: 0.7826\n",
      "Test accuracy: 78.2566%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.2116 - accuracy: 0.3172\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1116 - accuracy: 0.3172\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1097 - accuracy: 0.3172\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.1, 'optimizer': 'Adam', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.1082 - accuracy: 0.3172\n",
      "Test accuracy: 31.7197%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.0666 - accuracy: 0.7177\n",
      "Test accuracy: 71.7658%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.1, 'optimizer': 'SGD', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 1.0232 - accuracy: 0.7802\n",
      "Test accuracy: 78.0209%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.01}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 12.2125 - accuracy: 0.3432\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Training with params: {'epochs': 50, 'learning_rate': 0.1, 'optimizer': 'RMSprop', 'regularization': 0.001}\n",
      "1817/1817 [==============================] - 3s 2ms/step - loss: 2.2117 - accuracy: 0.3432\n",
      "Test accuracy: 34.3208%\n",
      "\n",
      "Best accuracy of Neural Network: 78.5886% with params: {'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'Adam', 'regularization': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Define grid search parameters\n",
    "param_grid_nn = {\n",
    "    'optimizer': ['Adam', 'SGD', 'RMSprop'],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'regularization': [0.01, 0.001],\n",
    "    'epochs': [10, 20, 30, 50]\n",
    "}\n",
    "\n",
    "# Initialize best accuracy and hyperparameters\n",
    "best_accuracy_nn = 0\n",
    "best_params_nn = {}\n",
    "best_model_path = 'Best_NN_model.h5'\n",
    "\n",
    "# Loop over parameter combinations\n",
    "for params in ParameterGrid(param_grid_nn):\n",
    "    print(f\"Training with params: {params}\")\n",
    "    \n",
    "    # Create model\n",
    "    model_NN = create_nn(input_shape, num_classes, params['optimizer'], params['learning_rate'], params['regularization'])\n",
    "    \n",
    "    # Train the model\n",
    "    history_NN = model_NN.fit(X_train, y_train, epochs=params['epochs'], batch_size=64, validation_split=0.1, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model_NN.evaluate(X_test, y_test)\n",
    "    print(f\"Test accuracy: {accuracy:.4%}\")\n",
    "    print()\n",
    "    \n",
    "    # Check if this model is the best so far\n",
    "    if accuracy > best_accuracy_nn:\n",
    "        best_accuracy_nn = accuracy\n",
    "        best_params_nn = params\n",
    "        \n",
    "        # Save the model\n",
    "        model_NN.save(best_model_path)\n",
    "        print(f\"Saved the best model with accuracy: {accuracy:.4%}\")\n",
    "\n",
    "print(f\"Best accuracy of Neural Network: {best_accuracy_nn:.4%} with params: {best_params_nn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e19144f-de0d-465e-8155-d9946faab822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1817/1817 [==============================] - 4s 2ms/step - loss: 1.0362 - accuracy: 0.7859\n",
      "Test accuracy: 78.5886%\n"
     ]
    }
   ],
   "source": [
    "best_model_path = 'Best_NN_model.h5'\n",
    "Best_Model_NN = tf.keras.models.load_model(best_model_path)\n",
    "\n",
    "loss, accuracy = Best_Model_NN.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy:.4%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
