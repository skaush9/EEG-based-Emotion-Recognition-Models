{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3865c62-0eed-4630-80cb-598602e55e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data\n",
    "\n",
    "import random\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be04b50-ba41-4b73-9bcc-c9edb341d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 examples of training data:\n",
      "[[26.94933313 26.94942352 26.86116345 ... 16.22032493 17.53295088\n",
      "  17.53075379]\n",
      " [26.95540644 26.95561349 26.86818211 ... 16.22077216 17.53405894\n",
      "  17.53186146]\n",
      " [26.96394591 26.96354065 26.87468671 ... 16.22162589 17.53570343\n",
      "  17.53347345]\n",
      " ...\n",
      " [26.95091461 26.95146416 26.85930528 ... 16.21242109 17.53291899\n",
      "  17.53075099]\n",
      " [26.93989902 26.94184343 26.84918537 ... 16.21115102 17.5320002\n",
      "  17.52995518]\n",
      " [26.92817907 26.9306008  26.83702679 ... 16.21079389 17.53139138\n",
      "  17.52946743]]\n",
      "\n",
      "Corresponding labels for the training data:\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "First 10 examples of test data:\n",
      "[[26.88684078 26.36006069 26.2375236  ... 16.32757215 16.90493887\n",
      "  16.7821357 ]\n",
      " [26.88612478 26.35698842 26.23444401 ... 16.33011158 16.90430262\n",
      "  16.78066285]\n",
      " [26.88125864 26.3487917  26.22622124 ... 16.33296166 16.90424512\n",
      "  16.77954978]\n",
      " ...\n",
      " [26.83513111 26.27179449 26.16101443 ... 16.31236921 16.87338631\n",
      "  16.74132307]\n",
      " [26.82404048 26.25446281 26.14994268 ... 16.30692625 16.86661873\n",
      "  16.73289937]\n",
      " [26.81532266 26.24281711 26.13940717 ... 16.30125824 16.85990699\n",
      "  16.72438165]]\n",
      "\n",
      "Corresponding labels for the test data:\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "Total number of samples in the dataset: 84420\n"
     ]
    }
   ],
   "source": [
    "data = load_data.read_data_sets()\n",
    "\n",
    "# get train data\n",
    "train_x = data.train.data\n",
    "\n",
    "# get train labels\n",
    "train_labels = data.train.labels\n",
    "\n",
    "# get test data\n",
    "test_x = data.test.data\n",
    "\n",
    "# get test labels\n",
    "test_labels = data.test.labels\n",
    "\n",
    "# get sample number\n",
    "n_samples = data.train.num_examples\n",
    "\n",
    "# Print the first 10 examples of training data and labels\n",
    "print(\"First 10 examples of training data:\")\n",
    "print(train_x[:10])\n",
    "print()\n",
    "\n",
    "print(\"Corresponding labels for the training data:\")\n",
    "print(train_labels[:10])\n",
    "print()\n",
    "\n",
    "# Print the first 10 examples of test data and labels\n",
    "print(\"First 10 examples of test data:\")\n",
    "print(test_x[:10])\n",
    "print()\n",
    "\n",
    "print(\"Corresponding labels for the test data:\")\n",
    "print(test_labels[:10])\n",
    "print()\n",
    "\n",
    "# Print the total number of samples in the dataset\n",
    "print(f\"Total number of samples in the dataset: {n_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dba713a-ea33-4f11-8ccd-58c26aa5cf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label counts: {0: 28602, 1: 26628, 2: 29190}\n",
      "Test label counts: {0: 18438, 1: 19740, 2: 19950}\n"
     ]
    }
   ],
   "source": [
    "# Count the unique labels in the training set\n",
    "unique_train, counts_train = np.unique(train_labels, return_counts=True)\n",
    "label_counts_train = dict(zip(unique_train, counts_train))\n",
    "\n",
    "# Count the unique labels in the test set\n",
    "unique_test, counts_test = np.unique(test_labels, return_counts=True)\n",
    "label_counts_test = dict(zip(unique_test, counts_test))\n",
    "\n",
    "print(\"Training label counts:\", label_counts_train)\n",
    "print(\"Test label counts:\", label_counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3092c09b-685e-4fc5-b2fe-2d5ef192e784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset has missing values\n",
    "missing_rows_count = np.isnan(train_x).any(axis=1).sum()\n",
    "print(f\"Number of rows with missing values: {missing_rows_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26099914-a673-436c-b598-2b06b5cd3b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label counts after balancing: {0: 29190, 1: 29190, 2: 29190}\n"
     ]
    }
   ],
   "source": [
    "# Balance the training data using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "balanced_train_x, balanced_train_labels = smote.fit_resample(train_x, train_labels)\n",
    "\n",
    "unique_train1, counts_train1 = np.unique(balanced_train_labels, return_counts=True)\n",
    "label_counts_train1 = dict(zip(unique_train1, counts_train1))\n",
    "\n",
    "print(\"Training label counts after balancing:\", label_counts_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a5544a-2637-4c00-b491-a63eb69672e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 shuffled training labels\n",
      "[2 1 0 2 1 1 1 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle indices\n",
    "indices = np.arange(balanced_train_x.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Use shuffled indices to shuffle train_x and train_labels\n",
    "balanced_train_x_shuffled = balanced_train_x[indices]\n",
    "balanced_train_labels_shuffled = balanced_train_labels[indices]\n",
    "\n",
    "# Print the first 10 examples of shuffled training labels\n",
    "print(\"First 10 shuffled training labels\")\n",
    "print(balanced_train_labels_shuffled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456b26f9-ed95-4bc7-8590-f68d4e65adb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "balanced_train_labels_shuffled_encoded = to_categorical(balanced_train_labels_shuffled, num_classes=3)\n",
    "test_labels_encoded = to_categorical(test_labels, num_classes=3)\n",
    "\n",
    "print(balanced_train_labels_shuffled_encoded[:10])\n",
    "print(test_labels_encoded[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a162d40-6a3a-445c-84cc-af60d920951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 examples of training data:\n",
      "[[ 0.277042    0.50842701  0.62010643 ...  0.64209086  0.95159286\n",
      "   1.29773046]\n",
      " [ 1.20097218  0.94460925  0.04775802 ...  2.15317899  2.39343114\n",
      "   1.9117267 ]\n",
      " [ 0.70658243  0.916921    0.90089585 ...  0.22706223  0.42912665\n",
      "   0.99304716]\n",
      " ...\n",
      " [-1.42407429 -1.20356438 -1.47922034 ... -1.39117253 -1.07304814\n",
      "  -0.60589379]\n",
      " [ 0.21515057  0.09690666  1.07862523 ...  2.31080528  2.38848611\n",
      "   1.92010694]\n",
      " [ 0.31519943  0.33099948  0.42231182 ...  0.22753281 -0.17277753\n",
      "   0.23854368]]\n",
      "\n",
      "Corresponding labels for the training data:\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "One-Hot encoded labels for the training data:\n",
      "[2 1 0 2 1 1 1 0 2 2]\n",
      "\n",
      "First 10 examples of test data:\n",
      "[[ 0.44138796 -0.00202854 -0.1746563  ... -0.41053994 -0.00116352\n",
      "  -0.22655811]\n",
      " [ 0.4407388  -0.00470152 -0.17757255 ... -0.40779565 -0.0018294\n",
      "  -0.22787341]\n",
      " [ 0.43632692 -0.01183294 -0.18535919 ... -0.40471564 -0.00188958\n",
      "  -0.22886742]\n",
      " ...\n",
      " [ 0.3945054  -0.07882315 -0.2471074  ... -0.42696935 -0.03418553\n",
      "  -0.26300493]\n",
      " [ 0.38445009 -0.09390231 -0.25759189 ... -0.4328514  -0.04126829\n",
      "  -0.27052752]\n",
      " [ 0.37654608 -0.10403446 -0.2675686  ... -0.43897667 -0.0482926\n",
      "  -0.27813409]]\n",
      "\n",
      "Corresponding labels for the test data:\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "One-Hot encoded labels for the test data:\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(balanced_train_x_shuffled)\n",
    "X_test = scaler.transform(test_x)\n",
    "\n",
    "y_train = balanced_train_labels_shuffled_encoded\n",
    "y_test = test_labels_encoded\n",
    "\n",
    "y_train1 = balanced_train_labels_shuffled\n",
    "y_test1 = test_labels\n",
    "\n",
    "print(\"First 10 examples of training data:\")\n",
    "print(X_train[:10])\n",
    "print()\n",
    "\n",
    "print(\"Corresponding labels for the training data:\")\n",
    "print(y_train[:10])\n",
    "print()\n",
    "\n",
    "print(\"One-Hot encoded labels for the training data:\")\n",
    "print(y_train1[:10])\n",
    "print()\n",
    "\n",
    "print(\"First 10 examples of test data:\")\n",
    "print(X_test[:10])\n",
    "print()\n",
    "\n",
    "print(\"Corresponding labels for the test data:\")\n",
    "print(y_test[:10])\n",
    "print()\n",
    "\n",
    "print(\"One-Hot encoded labels for the test data:\")\n",
    "print(y_test1[:10])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f381b0-5a77-4d77-a0a2-0939c630326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: {'C': 0.1, 'kernel': 'linear'}\n",
      "Test accuracy: 69.6876%\n",
      "Saved the best model with accuracy: 69.6876%\n",
      "\n",
      "Training with params: {'C': 0.1, 'kernel': 'rbf'}\n",
      "Test accuracy: 77.5117%\n",
      "Saved the best model with accuracy: 77.5117%\n",
      "\n",
      "Training with params: {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "Test accuracy: 52.5151%\n",
      "\n",
      "Training with params: {'C': 1, 'kernel': 'linear'}\n",
      "Test accuracy: 69.3779%\n",
      "\n",
      "Training with params: {'C': 1, 'kernel': 'rbf'}\n",
      "Test accuracy: 79.0996%\n",
      "Saved the best model with accuracy: 79.0996%\n",
      "\n",
      "Training with params: {'C': 1, 'kernel': 'sigmoid'}\n",
      "Test accuracy: 48.0457%\n",
      "\n",
      "Training with params: {'C': 10, 'kernel': 'linear'}\n",
      "Test accuracy: 69.2197%\n",
      "\n",
      "Training with params: {'C': 10, 'kernel': 'rbf'}\n",
      "Test accuracy: 78.9929%\n",
      "\n",
      "Training with params: {'C': 10, 'kernel': 'sigmoid'}\n",
      "Test accuracy: 47.9941%\n",
      "\n",
      "Training with params: {'C': 100, 'kernel': 'linear'}\n",
      "Test accuracy: 69.1990%\n",
      "\n",
      "Training with params: {'C': 100, 'kernel': 'rbf'}\n",
      "Test accuracy: 78.9791%\n",
      "\n",
      "Training with params: {'C': 100, 'kernel': 'sigmoid'}\n",
      "Test accuracy: 47.9786%\n",
      "\n",
      "Best accuracy of Support Vector Machine: 79.0996% with params: {'C': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Suppress convergence warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define grid search parameters for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Initialize best accuracy and hyperparameters\n",
    "best_accuracy_svm = 0\n",
    "best_params_svm = {}\n",
    "best_model_path = 'Best_SupportVectorMachine_model.pkl'\n",
    "\n",
    "# Loop over parameter combinations\n",
    "for params in [{'C': C, 'kernel': kernel} for C in param_grid_svm['C'] for kernel in param_grid_svm['kernel']]:\n",
    "    try:\n",
    "        print(f\"Training with params: {params}\")\n",
    "        \n",
    "        # Create the SVM model\n",
    "        svm = SVC(C=params['C'], kernel=params['kernel'], random_state=42)\n",
    "        \n",
    "        # Fit the model\n",
    "        svm.fit(X_train, y_train1)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred = svm.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test1, y_pred)\n",
    "        print(f\"Test accuracy: {accuracy:.4%}\")\n",
    "        \n",
    "        # Check if this model is the best so far\n",
    "        if accuracy > best_accuracy_svm:\n",
    "            best_accuracy_svm = accuracy\n",
    "            best_params_svm = params\n",
    "            joblib.dump(svm, best_model_path)\n",
    "            print(f\"Saved the best model with accuracy: {accuracy:.4%}\")\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping parameters {params} due to error: {e}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Best accuracy of Support Vector Machine: {best_accuracy_svm:.4%} with params: {best_params_svm}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
